<!doctype html>
<html data-n-head-ssr lang="en" amp data-n-head="%7B%22lang%22:%7B%22ssr%22:%22en%22%7D,%22amp%22:%7B%22ssr%22:true%7D%7D">
  <head>
    <title>A complete ML Pipeline study case&amp#58; Face and Emotion Recognition - Gioele Crispo</title><meta data-n-head="ssr" charset="utf-8"><meta data-n-head="ssr" name="robots" content="index,follow"><meta data-n-head="ssr" name="viewport" content="width=device-width,initial-scale=1"><meta data-n-head="ssr" data-hid="og:type" property="og:type" content="website"><meta data-n-head="ssr" data-hid="og:site_name" property="og:site_name" content="Gioele Crispo"><meta data-n-head="ssr" data-hid="og:title" property="og:title" content="A complete ML Pipeline study case&amp;#58; Face and Emotion Recognition - Gioele Crispo"><meta data-n-head="ssr" data-hid="description" name="description" content="A journey through the phases of data exploration and training of a CNN model from scratch. A particular focus on optimization for production with Optuna and ONNX is carried out."><meta data-n-head="ssr" data-hid="og:description" name="og:description" content="A journey through the phases of data exploration and training of a CNN model from scratch. A particular focus on optimization for production with Optuna and ONNX is carried out."><meta data-n-head="ssr" data-hid="og:url" property="og:url" content="https://gioelecrispo.github.io/blog/a-complete-ml-pipeline-study-case-face-and-emotion-recognition"><meta data-n-head="ssr" data-hid="og:image" property="og:image" content="/_nuxt/img/e47f985.jpg"><meta data-n-head="ssr" data-hid="twitter:card" property="twitter:card" content="summary_large_image"><meta data-n-head="ssr" data-hid="twitter:title" property="twitter:title" content="A complete ML Pipeline study case&amp;#58; Face and Emotion Recognition - Gioele Crispo"><meta data-n-head="ssr" data-hid="twitter:description" name="twitter:description" content="A journey through the phases of data exploration and training of a CNN model from scratch. A particular focus on optimization for production with Optuna and ONNX is carried out."><meta data-n-head="ssr" data-hid="twitter:image" property="twitter:image" content="/_nuxt/img/e47f985.jpg"><base href="/"><link data-n-head="ssr" rel="icon" type="image/png" href="/favicon.ico"><style data-n-head="vuetify" type="text/css" id="vuetify-theme-stylesheet" nonce="undefined">.v-application a{color:#2196f3}.v-application .primary{background-color:#2196f3!important;border-color:#2196f3!important}.v-application .primary--text{color:#2196f3!important;caret-color:#2196f3!important}.v-application .primary.lighten-5{background-color:#d4ffff!important;border-color:#d4ffff!important}.v-application .primary--text.text--lighten-5{color:#d4ffff!important;caret-color:#d4ffff!important}.v-application .primary.lighten-4{background-color:#b5ffff!important;border-color:#b5ffff!important}.v-application .primary--text.text--lighten-4{color:#b5ffff!important;caret-color:#b5ffff!important}.v-application .primary.lighten-3{background-color:#95e8ff!important;border-color:#95e8ff!important}.v-application .primary--text.text--lighten-3{color:#95e8ff!important;caret-color:#95e8ff!important}.v-application .primary.lighten-2{background-color:#75ccff!important;border-color:#75ccff!important}.v-application .primary--text.text--lighten-2{color:#75ccff!important;caret-color:#75ccff!important}.v-application .primary.lighten-1{background-color:#51b0ff!important;border-color:#51b0ff!important}.v-application .primary--text.text--lighten-1{color:#51b0ff!important;caret-color:#51b0ff!important}.v-application .primary.darken-1{background-color:#007cd6!important;border-color:#007cd6!important}.v-application .primary--text.text--darken-1{color:#007cd6!important;caret-color:#007cd6!important}.v-application .primary.darken-2{background-color:#0064ba!important;border-color:#0064ba!important}.v-application .primary--text.text--darken-2{color:#0064ba!important;caret-color:#0064ba!important}.v-application .primary.darken-3{background-color:#004d9f!important;border-color:#004d9f!important}.v-application .primary--text.text--darken-3{color:#004d9f!important;caret-color:#004d9f!important}.v-application .primary.darken-4{background-color:#003784!important;border-color:#003784!important}.v-application .primary--text.text--darken-4{color:#003784!important;caret-color:#003784!important}.v-application .secondary{background-color:#e91e63!important;border-color:#e91e63!important}.v-application .secondary--text{color:#e91e63!important;caret-color:#e91e63!important}.v-application .secondary.lighten-5{background-color:#ffc0e7!important;border-color:#ffc0e7!important}.v-application .secondary--text.text--lighten-5{color:#ffc0e7!important;caret-color:#ffc0e7!important}.v-application .secondary.lighten-4{background-color:#ffa3cb!important;border-color:#ffa3cb!important}.v-application .secondary--text.text--lighten-4{color:#ffa3cb!important;caret-color:#ffa3cb!important}.v-application .secondary.lighten-3{background-color:#ff85b0!important;border-color:#ff85b0!important}.v-application .secondary--text.text--lighten-3{color:#ff85b0!important;caret-color:#ff85b0!important}.v-application .secondary.lighten-2{background-color:#ff6795!important;border-color:#ff6795!important}.v-application .secondary--text.text--lighten-2{color:#ff6795!important;caret-color:#ff6795!important}.v-application .secondary.lighten-1{background-color:#ff467c!important;border-color:#ff467c!important}.v-application .secondary--text.text--lighten-1{color:#ff467c!important;caret-color:#ff467c!important}.v-application .secondary.darken-1{background-color:#c9004b!important;border-color:#c9004b!important}.v-application .secondary--text.text--darken-1{color:#c9004b!important;caret-color:#c9004b!important}.v-application .secondary.darken-2{background-color:#aa0035!important;border-color:#aa0035!important}.v-application .secondary--text.text--darken-2{color:#aa0035!important;caret-color:#aa0035!important}.v-application .secondary.darken-3{background-color:#8b0021!important;border-color:#8b0021!important}.v-application .secondary--text.text--darken-3{color:#8b0021!important;caret-color:#8b0021!important}.v-application .secondary.darken-4{background-color:#6c000a!important;border-color:#6c000a!important}.v-application .secondary--text.text--darken-4{color:#6c000a!important;caret-color:#6c000a!important}.v-application .accent{background-color:#82b1ff!important;border-color:#82b1ff!important}.v-application .accent--text{color:#82b1ff!important;caret-color:#82b1ff!important}.v-application .accent.lighten-5{background-color:#fff!important;border-color:#fff!important}.v-application .accent--text.text--lighten-5{color:#fff!important;caret-color:#fff!important}.v-application .accent.lighten-4{background-color:#f8ffff!important;border-color:#f8ffff!important}.v-application .accent--text.text--lighten-4{color:#f8ffff!important;caret-color:#f8ffff!important}.v-application .accent.lighten-3{background-color:#daffff!important;border-color:#daffff!important}.v-application .accent--text.text--lighten-3{color:#daffff!important;caret-color:#daffff!important}.v-application .accent.lighten-2{background-color:#bce8ff!important;border-color:#bce8ff!important}.v-application .accent--text.text--lighten-2{color:#bce8ff!important;caret-color:#bce8ff!important}.v-application .accent.lighten-1{background-color:#9fccff!important;border-color:#9fccff!important}.v-application .accent--text.text--lighten-1{color:#9fccff!important;caret-color:#9fccff!important}.v-application .accent.darken-1{background-color:#6596e2!important;border-color:#6596e2!important}.v-application .accent--text.text--darken-1{color:#6596e2!important;caret-color:#6596e2!important}.v-application .accent.darken-2{background-color:#467dc6!important;border-color:#467dc6!important}.v-application .accent--text.text--darken-2{color:#467dc6!important;caret-color:#467dc6!important}.v-application .accent.darken-3{background-color:#2364aa!important;border-color:#2364aa!important}.v-application .accent--text.text--darken-3{color:#2364aa!important;caret-color:#2364aa!important}.v-application .accent.darken-4{background-color:#004c90!important;border-color:#004c90!important}.v-application .accent--text.text--darken-4{color:#004c90!important;caret-color:#004c90!important}.v-application .error{background-color:#ff5252!important;border-color:#ff5252!important}.v-application .error--text{color:#ff5252!important;caret-color:#ff5252!important}.v-application .error.lighten-5{background-color:#ffe4d5!important;border-color:#ffe4d5!important}.v-application .error--text.text--lighten-5{color:#ffe4d5!important;caret-color:#ffe4d5!important}.v-application .error.lighten-4{background-color:#ffc6b9!important;border-color:#ffc6b9!important}.v-application .error--text.text--lighten-4{color:#ffc6b9!important;caret-color:#ffc6b9!important}.v-application .error.lighten-3{background-color:#ffa99e!important;border-color:#ffa99e!important}.v-application .error--text.text--lighten-3{color:#ffa99e!important;caret-color:#ffa99e!important}.v-application .error.lighten-2{background-color:#ff8c84!important;border-color:#ff8c84!important}.v-application .error--text.text--lighten-2{color:#ff8c84!important;caret-color:#ff8c84!important}.v-application .error.lighten-1{background-color:#ff6f6a!important;border-color:#ff6f6a!important}.v-application .error--text.text--lighten-1{color:#ff6f6a!important;caret-color:#ff6f6a!important}.v-application .error.darken-1{background-color:#df323b!important;border-color:#df323b!important}.v-application .error--text.text--darken-1{color:#df323b!important;caret-color:#df323b!important}.v-application .error.darken-2{background-color:#bf0025!important;border-color:#bf0025!important}.v-application .error--text.text--darken-2{color:#bf0025!important;caret-color:#bf0025!important}.v-application .error.darken-3{background-color:#9f0010!important;border-color:#9f0010!important}.v-application .error--text.text--darken-3{color:#9f0010!important;caret-color:#9f0010!important}.v-application .error.darken-4{background-color:maroon!important;border-color:maroon!important}.v-application .error--text.text--darken-4{color:maroon!important;caret-color:maroon!important}.v-application .info{background-color:#2196f3!important;border-color:#2196f3!important}.v-application .info--text{color:#2196f3!important;caret-color:#2196f3!important}.v-application .info.lighten-5{background-color:#d4ffff!important;border-color:#d4ffff!important}.v-application .info--text.text--lighten-5{color:#d4ffff!important;caret-color:#d4ffff!important}.v-application .info.lighten-4{background-color:#b5ffff!important;border-color:#b5ffff!important}.v-application .info--text.text--lighten-4{color:#b5ffff!important;caret-color:#b5ffff!important}.v-application .info.lighten-3{background-color:#95e8ff!important;border-color:#95e8ff!important}.v-application .info--text.text--lighten-3{color:#95e8ff!important;caret-color:#95e8ff!important}.v-application .info.lighten-2{background-color:#75ccff!important;border-color:#75ccff!important}.v-application .info--text.text--lighten-2{color:#75ccff!important;caret-color:#75ccff!important}.v-application .info.lighten-1{background-color:#51b0ff!important;border-color:#51b0ff!important}.v-application .info--text.text--lighten-1{color:#51b0ff!important;caret-color:#51b0ff!important}.v-application .info.darken-1{background-color:#007cd6!important;border-color:#007cd6!important}.v-application .info--text.text--darken-1{color:#007cd6!important;caret-color:#007cd6!important}.v-application .info.darken-2{background-color:#0064ba!important;border-color:#0064ba!important}.v-application .info--text.text--darken-2{color:#0064ba!important;caret-color:#0064ba!important}.v-application .info.darken-3{background-color:#004d9f!important;border-color:#004d9f!important}.v-application .info--text.text--darken-3{color:#004d9f!important;caret-color:#004d9f!important}.v-application .info.darken-4{background-color:#003784!important;border-color:#003784!important}.v-application .info--text.text--darken-4{color:#003784!important;caret-color:#003784!important}.v-application .success{background-color:#4caf50!important;border-color:#4caf50!important}.v-application .success--text{color:#4caf50!important;caret-color:#4caf50!important}.v-application .success.lighten-5{background-color:#dcffd6!important;border-color:#dcffd6!important}.v-application .success--text.text--lighten-5{color:#dcffd6!important;caret-color:#dcffd6!important}.v-application .success.lighten-4{background-color:#beffba!important;border-color:#beffba!important}.v-application .success--text.text--lighten-4{color:#beffba!important;caret-color:#beffba!important}.v-application .success.lighten-3{background-color:#a2ff9e!important;border-color:#a2ff9e!important}.v-application .success--text.text--lighten-3{color:#a2ff9e!important;caret-color:#a2ff9e!important}.v-application .success.lighten-2{background-color:#85e783!important;border-color:#85e783!important}.v-application .success--text.text--lighten-2{color:#85e783!important;caret-color:#85e783!important}.v-application .success.lighten-1{background-color:#69cb69!important;border-color:#69cb69!important}.v-application .success--text.text--lighten-1{color:#69cb69!important;caret-color:#69cb69!important}.v-application .success.darken-1{background-color:#2d9437!important;border-color:#2d9437!important}.v-application .success--text.text--darken-1{color:#2d9437!important;caret-color:#2d9437!important}.v-application .success.darken-2{background-color:#00791e!important;border-color:#00791e!important}.v-application .success--text.text--darken-2{color:#00791e!important;caret-color:#00791e!important}.v-application .success.darken-3{background-color:#006000!important;border-color:#006000!important}.v-application .success--text.text--darken-3{color:#006000!important;caret-color:#006000!important}.v-application .success.darken-4{background-color:#004700!important;border-color:#004700!important}.v-application .success--text.text--darken-4{color:#004700!important;caret-color:#004700!important}.v-application .warning{background-color:#ffc107!important;border-color:#ffc107!important}.v-application .warning--text{color:#ffc107!important;caret-color:#ffc107!important}.v-application .warning.lighten-5{background-color:#ffffae!important;border-color:#ffffae!important}.v-application .warning--text.text--lighten-5{color:#ffffae!important;caret-color:#ffffae!important}.v-application .warning.lighten-4{background-color:#ffff91!important;border-color:#ffff91!important}.v-application .warning--text.text--lighten-4{color:#ffff91!important;caret-color:#ffff91!important}.v-application .warning.lighten-3{background-color:#ffff74!important;border-color:#ffff74!important}.v-application .warning--text.text--lighten-3{color:#ffff74!important;caret-color:#ffff74!important}.v-application .warning.lighten-2{background-color:#fff956!important;border-color:#fff956!important}.v-application .warning--text.text--lighten-2{color:#fff956!important;caret-color:#fff956!important}.v-application .warning.lighten-1{background-color:#ffdd37!important;border-color:#ffdd37!important}.v-application .warning--text.text--lighten-1{color:#ffdd37!important;caret-color:#ffdd37!important}.v-application .warning.darken-1{background-color:#e0a600!important;border-color:#e0a600!important}.v-application .warning--text.text--darken-1{color:#e0a600!important;caret-color:#e0a600!important}.v-application .warning.darken-2{background-color:#c18c00!important;border-color:#c18c00!important}.v-application .warning--text.text--darken-2{color:#c18c00!important;caret-color:#c18c00!important}.v-application .warning.darken-3{background-color:#a27300!important;border-color:#a27300!important}.v-application .warning--text.text--darken-3{color:#a27300!important;caret-color:#a27300!important}.v-application .warning.darken-4{background-color:#855a00!important;border-color:#855a00!important}.v-application .warning--text.text--darken-4{color:#855a00!important;caret-color:#855a00!important}.v-application .toolbars{background-color:#fff!important;border-color:#fff!important}.v-application .toolbars--text{color:#fff!important;caret-color:#fff!important}.v-application .toolbars.lighten-5{background-color:#fff!important;border-color:#fff!important}.v-application .toolbars--text.text--lighten-5{color:#fff!important;caret-color:#fff!important}.v-application .toolbars.lighten-4{background-color:#fff!important;border-color:#fff!important}.v-application .toolbars--text.text--lighten-4{color:#fff!important;caret-color:#fff!important}.v-application .toolbars.lighten-3{background-color:#fff!important;border-color:#fff!important}.v-application .toolbars--text.text--lighten-3{color:#fff!important;caret-color:#fff!important}.v-application .toolbars.lighten-2{background-color:#fff!important;border-color:#fff!important}.v-application .toolbars--text.text--lighten-2{color:#fff!important;caret-color:#fff!important}.v-application .toolbars.lighten-1{background-color:#fff!important;border-color:#fff!important}.v-application .toolbars--text.text--lighten-1{color:#fff!important;caret-color:#fff!important}.v-application .toolbars.darken-1{background-color:#e2e2e2!important;border-color:#e2e2e2!important}.v-application .toolbars--text.text--darken-1{color:#e2e2e2!important;caret-color:#e2e2e2!important}.v-application .toolbars.darken-2{background-color:#c6c6c6!important;border-color:#c6c6c6!important}.v-application .toolbars--text.text--darken-2{color:#c6c6c6!important;caret-color:#c6c6c6!important}.v-application .toolbars.darken-3{background-color:#ababab!important;border-color:#ababab!important}.v-application .toolbars--text.text--darken-3{color:#ababab!important;caret-color:#ababab!important}.v-application .toolbars.darken-4{background-color:#919191!important;border-color:#919191!important}.v-application .toolbars--text.text--darken-4{color:#919191!important;caret-color:#919191!important}.v-application .homeSectionPrimary{background-color:#fff!important;border-color:#fff!important}.v-application .homeSectionPrimary--text{color:#fff!important;caret-color:#fff!important}.v-application .homeSectionPrimary.lighten-5{background-color:#fff!important;border-color:#fff!important}.v-application .homeSectionPrimary--text.text--lighten-5{color:#fff!important;caret-color:#fff!important}.v-application .homeSectionPrimary.lighten-4{background-color:#fff!important;border-color:#fff!important}.v-application .homeSectionPrimary--text.text--lighten-4{color:#fff!important;caret-color:#fff!important}.v-application .homeSectionPrimary.lighten-3{background-color:#fff!important;border-color:#fff!important}.v-application .homeSectionPrimary--text.text--lighten-3{color:#fff!important;caret-color:#fff!important}.v-application .homeSectionPrimary.lighten-2{background-color:#fff!important;border-color:#fff!important}.v-application .homeSectionPrimary--text.text--lighten-2{color:#fff!important;caret-color:#fff!important}.v-application .homeSectionPrimary.lighten-1{background-color:#fff!important;border-color:#fff!important}.v-application .homeSectionPrimary--text.text--lighten-1{color:#fff!important;caret-color:#fff!important}.v-application .homeSectionPrimary.darken-1{background-color:#e2e2e2!important;border-color:#e2e2e2!important}.v-application .homeSectionPrimary--text.text--darken-1{color:#e2e2e2!important;caret-color:#e2e2e2!important}.v-application .homeSectionPrimary.darken-2{background-color:#c6c6c6!important;border-color:#c6c6c6!important}.v-application .homeSectionPrimary--text.text--darken-2{color:#c6c6c6!important;caret-color:#c6c6c6!important}.v-application .homeSectionPrimary.darken-3{background-color:#ababab!important;border-color:#ababab!important}.v-application .homeSectionPrimary--text.text--darken-3{color:#ababab!important;caret-color:#ababab!important}.v-application .homeSectionPrimary.darken-4{background-color:#919191!important;border-color:#919191!important}.v-application .homeSectionPrimary--text.text--darken-4{color:#919191!important;caret-color:#919191!important}.v-application .homeSectionSecondary{background-color:#efefef!important;border-color:#efefef!important}.v-application .homeSectionSecondary--text{color:#efefef!important;caret-color:#efefef!important}.v-application .homeSectionSecondary.lighten-5{background-color:#fff!important;border-color:#fff!important}.v-application .homeSectionSecondary--text.text--lighten-5{color:#fff!important;caret-color:#fff!important}.v-application .homeSectionSecondary.lighten-4{background-color:#fff!important;border-color:#fff!important}.v-application .homeSectionSecondary--text.text--lighten-4{color:#fff!important;caret-color:#fff!important}.v-application .homeSectionSecondary.lighten-3{background-color:#fff!important;border-color:#fff!important}.v-application .homeSectionSecondary--text.text--lighten-3{color:#fff!important;caret-color:#fff!important}.v-application .homeSectionSecondary.lighten-2{background-color:#fff!important;border-color:#fff!important}.v-application .homeSectionSecondary--text.text--lighten-2{color:#fff!important;caret-color:#fff!important}.v-application .homeSectionSecondary.lighten-1{background-color:#fff!important;border-color:#fff!important}.v-application .homeSectionSecondary--text.text--lighten-1{color:#fff!important;caret-color:#fff!important}.v-application .homeSectionSecondary.darken-1{background-color:#d3d3d3!important;border-color:#d3d3d3!important}.v-application .homeSectionSecondary--text.text--darken-1{color:#d3d3d3!important;caret-color:#d3d3d3!important}.v-application .homeSectionSecondary.darken-2{background-color:#b7b7b7!important;border-color:#b7b7b7!important}.v-application .homeSectionSecondary--text.text--darken-2{color:#b7b7b7!important;caret-color:#b7b7b7!important}.v-application .homeSectionSecondary.darken-3{background-color:#9c9c9c!important;border-color:#9c9c9c!important}.v-application .homeSectionSecondary--text.text--darken-3{color:#9c9c9c!important;caret-color:#9c9c9c!important}.v-application .homeSectionSecondary.darken-4{background-color:#828282!important;border-color:#828282!important}.v-application .homeSectionSecondary--text.text--darken-4{color:#828282!important;caret-color:#828282!important}</style><link rel="preload" href="/_nuxt/64d805e.js" as="script"><link rel="preload" href="/_nuxt/96c6ddd.js" as="script"><link rel="preload" href="/_nuxt/css/df62446.css" as="style"><link rel="preload" href="/_nuxt/19e3453.js" as="script"><link rel="preload" href="/_nuxt/css/6319521.css" as="style"><link rel="preload" href="/_nuxt/1e35afa.js" as="script"><link rel="preload" href="/_nuxt/bbb0136.js" as="script"><link rel="stylesheet" href="/_nuxt/css/df62446.css"><link rel="stylesheet" href="/_nuxt/css/6319521.css"><link rel="preload" href="/_nuxt/static/1648122739/blog/a-complete-ml-pipeline-study-case-face-and-emotion-recognition/state.js" as="script"><link rel="preload" href="/_nuxt/static/1648122739/blog/a-complete-ml-pipeline-study-case-face-and-emotion-recognition/payload.js" as="script"><link rel="preload" href="/_nuxt/static/1648122739/manifest.js" as="script">
  </head>
  <body>
    <div data-server-rendered="true" id="__nuxt"><!----><div id="__layout"><div data-app="true" id="app-post" class="v-application v-application--is-ltr theme--light" data-v-e6ffbd9e><div class="v-application--wrap"><nav class="v-navigation-drawer v-navigation-drawer--close v-navigation-drawer--fixed v-navigation-drawer--is-mobile theme--light" style="height:100vh;top:0;transform:translateX(-100%);width:100%" data-v-6573dd40 data-v-e6ffbd9e><div class="v-navigation-drawer__content"><div class="container container--fluid" data-v-6573dd40><div class="row mr-3 justify-end" data-v-6573dd40><button type="button" class="v-btn v-btn--icon v-btn--round theme--light v-size--default" data-v-6573dd40><span class="v-btn__content"><i aria-hidden="true" class="v-icon notranslate mdi mdi-close theme--light" data-v-6573dd40></i></span></button></div> <div class="row" data-v-6573dd40><div class="col-sm-6 col-12" data-v-6573dd40><div class="container container--fluid fill-height" data-v-6573dd40><div class="row pt-6 align-center justify-center" data-v-6573dd40><div class="v-avatar" style="height:144px;min-width:144px;width:144px" data-v-6573dd40><img src="/_nuxt/img/9d8aa01.jpg" alt="Gioele Crispo" data-v-6573dd40></div></div></div></div> <div class="col-sm-6 col-12" data-v-6573dd40><div class="v-list pt-6 mt-0 v-sheet theme--light rounded v-list--dense v-list--rounded" data-v-6573dd40><div role="listbox" class="v-item-group theme--light v-list-item-group" data-v-6573dd40><a href="/" tabindex="0" class="text-center v-list-item v-list-item--link theme--light" data-v-6573dd40><div class="row" data-v-6573dd40><div class="col col-12" data-v-6573dd40><div class="row justify-center" data-v-6573dd40><i aria-hidden="true" class="v-icon notranslate mr-4 mdi mdi-home theme--light" data-v-6573dd40></i>
                                        Home
                                    </div></div></div></a><a href="/cv" tabindex="0" class="text-center v-list-item v-list-item--link theme--light" data-v-6573dd40><div class="row" data-v-6573dd40><div class="col col-12" data-v-6573dd40><div class="row justify-center" data-v-6573dd40><i aria-hidden="true" class="v-icon notranslate mr-4 mdi mdi-timeline-text theme--light" data-v-6573dd40></i>
                                        Curriculum Vitae
                                    </div></div></div></a><a href="/projects" tabindex="0" class="text-center v-list-item v-list-item--link theme--light" data-v-6573dd40><div class="row" data-v-6573dd40><div class="col col-12" data-v-6573dd40><div class="row justify-center" data-v-6573dd40><i aria-hidden="true" class="v-icon notranslate mr-4 mdi mdi-briefcase-outline theme--light" data-v-6573dd40></i>
                                        Projects
                                    </div></div></div></a><a href="/github" tabindex="0" class="text-center v-list-item v-list-item--link theme--light" data-v-6573dd40><div class="row" data-v-6573dd40><div class="col col-12" data-v-6573dd40><div class="row justify-center" data-v-6573dd40><i aria-hidden="true" class="v-icon notranslate mr-4 mdi mdi-github theme--light" data-v-6573dd40></i>
                                        Github
                                    </div></div></div></a><a href="/blog" aria-current="page" tabindex="0" class="text-center v-item--active v-list-item--active v-list-item v-list-item--link theme--light" data-v-6573dd40><div class="row" data-v-6573dd40><div class="col col-12" data-v-6573dd40><div class="row justify-center" data-v-6573dd40><i aria-hidden="true" class="v-icon notranslate mr-4 mdi mdi-file-document-outline theme--light" data-v-6573dd40></i>
                                        Blog
                                    </div></div></div></a></div></div></div></div></div></div><div class="v-navigation-drawer__border"></div></nav> <header id="app-toolbar" class="v-sheet theme--dark v-toolbar v-toolbar--prominent v-app-bar v-app-bar--fade-img-on-scroll v-app-bar--elevate-on-scroll v-app-bar--fixed v-app-bar--hide-shadow v-app-bar--shrink-on-scroll primary" style="height:350px;font-size:1.5rem;margin-top:0;transform:translateY(0);left:0;right:0" data-v-dde7e072 data-v-e6ffbd9e><div class="v-toolbar__image" style="opacity:1"><div class="v-image v-responsive theme--dark" style="height:350px" data-v-dde7e072><div class="v-image__image v-image__image--preload v-image__image--cover" style="background-image:linear-gradient(to top right,rgba(0,100,205,.7),rgba(0,2,216,.7));background-position:center center"></div><div class="v-responsive__content"></div></div></div><div class="v-toolbar__content" style="height:350px"> <button type="button" class="v-btn v-btn--icon v-btn--round theme--dark v-size--default" data-v-dde7e072><span class="v-btn__content"><i aria-hidden="true" class="v-icon notranslate mdi mdi-menu theme--dark" data-v-dde7e072></i></span></button> <div class="v-toolbar__title pl-1 pr-3" data-v-dde7e072><h3 data-v-dde7e072>Post</h3></div> <div class="spacer" data-v-dde7e072></div> <div class="row align-center justify-end" data-v-dde7e072><button type="button" class="v-btn v-btn--icon v-btn--round theme--dark v-size--default" data-v-dde7e072><span class="v-btn__content"><i aria-hidden="true" class="v-icon notranslate far fa-moon theme--dark" data-v-dde7e072></i></span></button> <!----><!----><!----><!----><!----></div></div></header> <main class="v-main" style="padding-top:350px;padding-right:0;padding-bottom:0;padding-left:0" data-v-e6ffbd9e><div class="v-main__wrap"><div id="app-content" class="container" data-v-dc1391fc data-v-dc1391fc data-v-e6ffbd9e><div class="row pa-0 ma-0" data-v-dc1391fc data-v-dc1391fc><div class="container container--fluid" data-v-127ef020 data-v-127ef020 data-v-dc1391fc data-v-dc1391fc><div class="row mt-8 justify-center" data-v-127ef020 data-v-127ef020><div class="col-lg-10 col-xl-9 col" data-v-127ef020 data-v-127ef020><div class="pa-0 py-2 mb-8 v-card v-sheet theme--light elevation-0 transparent" style="height:30px" data-v-127ef020><div class="v-card__title px-0 py-0 secondary--text" data-v-127ef020>#computer-vision, #mlops
                </div> <div class="v-card__text px-0 py-0 grey--text" data-v-127ef020>Written on: December 27, 2021
                </div> <div class="v-card__text px-0 py-0 grey--text" data-v-127ef020>Latest update: March 24, 2022
                </div></div> <article class="pt-12" data-v-127ef020><div class="nuxt-content" data-v-127ef020 data-v-127ef020><h1 id="a-complete-ml-pipeline-study-case-face-and-emotion-recognition" data-v-127ef020 data-v-127ef020><a href="#a-complete-ml-pipeline-study-case-face-and-emotion-recognition" aria-hidden="true" tabindex="-1" data-v-127ef020 data-v-127ef020><span class="icon icon-link" data-v-127ef020 data-v-127ef020></span></a>A complete ML Pipeline study case: Face and Emotion recognition</h1>
<br data-v-127ef020 data-v-127ef020>
<ul data-v-127ef020 data-v-127ef020>
<li data-v-127ef020 data-v-127ef020>Introduction</li>
<li data-v-127ef020 data-v-127ef020>The study case: Face and Emotion recognition with a CNN</li>
<li data-v-127ef020 data-v-127ef020>Do not forgive <strong data-v-127ef020 data-v-127ef020>Optimization</strong></li>
<li data-v-127ef020 data-v-127ef020>Prepare for production with <strong data-v-127ef020 data-v-127ef020>ONNX</strong></li>
<li data-v-127ef020 data-v-127ef020>Conclusions</li>
</ul>
<br data-v-127ef020 data-v-127ef020>
<h2 id="introduction" data-v-127ef020 data-v-127ef020><a href="#introduction" aria-hidden="true" tabindex="-1" data-v-127ef020 data-v-127ef020><span class="icon icon-link" data-v-127ef020 data-v-127ef020></span></a>Introduction</h2>
<p data-v-127ef020 data-v-127ef020>This post describes a project I made with my girlfriend, aiming to perform face and
emotion recognition through a Kinect sensor or a generic webcam.</p>
<p data-v-127ef020 data-v-127ef020>The emotion supported are: <code data-v-127ef020 data-v-127ef020>Happy</code>, <code data-v-127ef020 data-v-127ef020>Sad</code>, <code data-v-127ef020 data-v-127ef020>Disgust</code>, <code data-v-127ef020 data-v-127ef020>Neutral</code>, <code data-v-127ef020 data-v-127ef020>Fear</code>, <code data-v-127ef020 data-v-127ef020>Angry</code>,
<code data-v-127ef020 data-v-127ef020>Surprise</code>. The depth camera of the Kinect Sensor is used to carry out Depth
Segmentation and reduce face detection false positives. In addition, a confirmation
window is used to stabilize the model's predictions.</p>
<p data-v-127ef020 data-v-127ef020>The model used is a CNN built from scratch and trained on FER 2013 Dataset. Then, an
optimization phase has been performed to obtain the best hyperparameters.
The following <a href="https://www.youtube.com/watch?v=kOJncJAVPng" data-v-127ef020 data-v-127ef020>video</a> shows
the results of our work.</p>
<div style="text-align:center;width:100%" data-v-127ef020 data-v-127ef020>
<iframe src="https://www.youtube.com/embed/kOJncJAVPng" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen style="max-width:650px;height:auto" data-v-127ef020 data-v-127ef020>
</iframe>
<p data-v-127ef020 data-v-127ef020><br data-v-127ef020 data-v-127ef020><br data-v-127ef020 data-v-127ef020></p>
</div>
<h2 id="the-study-case-face-and-emotion-recognition-with-a-cnn" data-v-127ef020 data-v-127ef020><a href="#the-study-case-face-and-emotion-recognition-with-a-cnn" aria-hidden="true" tabindex="-1" data-v-127ef020 data-v-127ef020><span class="icon icon-link" data-v-127ef020 data-v-127ef020></span></a>The study case: Face and Emotion recognition with a CNN</h2>
<p data-v-127ef020 data-v-127ef020>In this section, we describe the step we followed to train the face recognition and emotion
recognition models and use them on a video stream capture from a Camera / Kinect.</p>
<h3 id="face-detection-and-recognition-dataset-acquisition" data-v-127ef020 data-v-127ef020><a href="#face-detection-and-recognition-dataset-acquisition" aria-hidden="true" tabindex="-1" data-v-127ef020 data-v-127ef020><span class="icon icon-link" data-v-127ef020 data-v-127ef020></span></a>Face Detection and Recognition: Dataset acquisition</h3>
<p data-v-127ef020 data-v-127ef020>To train face recognition we created a script that allowed us to collect images of a
person's faces. The script must be configured by passing as parameters the name and the
number of photos to be saved. The process uses opencv's face detector to automatically
extract faces and save them by labeling with the name entered.
This also allowed us to quickly review the saved photos and delete dirty data if any.
To have good recognition performance we used about 100 photos per person; results clearly
vary in different lighting conditions.</p>
<h3 id="face-detection-and-recognition-train-and-evaluation" data-v-127ef020 data-v-127ef020><a href="#face-detection-and-recognition-train-and-evaluation" aria-hidden="true" tabindex="-1" data-v-127ef020 data-v-127ef020><span class="icon icon-link" data-v-127ef020 data-v-127ef020></span></a>Face Detection and Recognition: Train and evaluation</h3>
<p data-v-127ef020 data-v-127ef020>The training of opencv's LBPHFaceRecognizer is very quick. We trained it on two different
faces, but it's scalable on multiple faces.</p>
<p data-v-127ef020 data-v-127ef020>For the inference phase we used the labels extracted from the LBPHFaceRecognizer of
opencv trained as described in the previous point to create <strong data-v-127ef020 data-v-127ef020>Confirmation Windows</strong> for
each person and then isolate the emotions based on the detected face.
More details on the Confirmation Windows will be given later.</p>
<h3 id="emotions-recognition-data-exploration-and-processing" data-v-127ef020 data-v-127ef020><a href="#emotions-recognition-data-exploration-and-processing" aria-hidden="true" tabindex="-1" data-v-127ef020 data-v-127ef020><span class="icon icon-link" data-v-127ef020 data-v-127ef020></span></a>Emotions Recognition: Data Exploration and Processing</h3>
<p data-v-127ef020 data-v-127ef020>We used FER2013 dataset. As a first step, we analyzed the dataset to verify its
distribution and check its content, displaying some images.</p>
<p data-v-127ef020 data-v-127ef020>We noticed that it is a very difficult dataset, since it has 3 main issues:</p>
<ol data-v-127ef020 data-v-127ef020>
<li data-v-127ef020 data-v-127ef020>It is very <strong data-v-127ef020 data-v-127ef020>unbalanced</strong>, as shown in Fig. 1;</li>
<li data-v-127ef020 data-v-127ef020>The images it contains are <strong data-v-127ef020 data-v-127ef020>dirty</strong> (some images are cartoons) or have noise (for
example writing or hands on the face). Refer to images contoured by red and blue rectangles in Fig. 2;</li>
<li data-v-127ef020 data-v-127ef020>Some <strong data-v-127ef020 data-v-127ef020>images could be misclassified</strong> (e.g. some emotion tagged as "fear" could be
classified as "surprise"). Refer to images contoured by green rectangles in Fig. 2.</li>
</ol>
<div style="text-align:center" data-v-127ef020 data-v-127ef020>
<img src="https://i.ibb.co/dMWP6QX/data-distribution.png" alt="distribution" width="80%" data-v-127ef020 data-v-127ef020> 
<p data-v-127ef020 data-v-127ef020><span style="font-size:12px" data-v-127ef020 data-v-127ef020>Fig. 1. Distribution of the dataset. There is a predominance of "Happy" and "Neutral"</span>
<br data-v-127ef020 data-v-127ef020></p>
</div>
<div style="text-align:center" data-v-127ef020 data-v-127ef020>
<img src="https://i.ibb.co/3hSp7dM/dataset-angry.png" alt="distribution" width="80%" data-v-127ef020 data-v-127ef020> 
<p data-v-127ef020 data-v-127ef020><span style="font-size:12px" data-v-127ef020 data-v-127ef020>Fig. 2. Some examples of images belonging to "Angry" emotion.
The red rectangle indicates an image taken from a cartoon. The blue rectangles are around images soiled by writing.
Finally, it is difficult to say if the woman in the green rectangle on the right is angry or shocked; the emotion of the man on the second row on the right could be considered also "Happy".</span>
<br data-v-127ef020 data-v-127ef020></p>
</div>
<br data-v-127ef020 data-v-127ef020>
<br data-v-127ef020 data-v-127ef020>
<p data-v-127ef020 data-v-127ef020>In fact, as mentioned in <a href="http://cs230.stanford.edu/projects_winter_2020/reports/32610274.pdf" rel="nofollow noopener noreferrer" target="_blank" data-v-127ef020 data-v-127ef020>this paper (sec. III)</a>,
the human accuracy on this dataset is about 65%.</p>
<p data-v-127ef020 data-v-127ef020>The dataset is already divided into train, validation and test and we made sure that the
three sets had the same distribution.
We then decided to merge the train and validation sets together, in order to be free
in choosing the percentage to be allocated to the validation set.</p>
<p data-v-127ef020 data-v-127ef020>Finally, we decided not to use oversampling techniques and to use the as-is dataset,
to try to get the most out of the CNN network and the training process, without adding
new data.</p>
<h3 id="emotions-recognition-training-and-evaluation" data-v-127ef020 data-v-127ef020><a href="#emotions-recognition-training-and-evaluation" aria-hidden="true" tabindex="-1" data-v-127ef020 data-v-127ef020><span class="icon icon-link" data-v-127ef020 data-v-127ef020></span></a>Emotions Recognition: Training and Evaluation</h3>
<p data-v-127ef020 data-v-127ef020>We used a CNN built from scratch, consisting of four convolution layers and two dense
layers. We verified that the model was sufficiently powerful and we managed overfitting
with regularization techniques such as l2 and dropout.</p>
<p data-v-127ef020 data-v-127ef020>The dataset has been divided into 70% for training, 20% for validation and 10% for testing,
respectively. In the training phase, we used Keras' <code data-v-127ef020 data-v-127ef020>ImageDataGenerator</code> utilities
to do some data augmentation and add zoomed and horizontally mirrored images.
This allowed us to increase the test performance a bit.</p>
<p data-v-127ef020 data-v-127ef020>We have optimized the hyperparameters of the model through the use of <code data-v-127ef020 data-v-127ef020>Optuna</code>;
details on hyperparameters and ranges will be given later.</p>
<p data-v-127ef020 data-v-127ef020>In the evaluation phase, we plotted a normalized confusion matrix to understand the
performance of the model relative to each class. The results were what we expected: a
strong polarization towards the most populous classes and an average error spread across
all them. In fact, the performance mirrors the challenges of the dataset.</p>
<div style="text-align:center" data-v-127ef020 data-v-127ef020>
<img src="https://i.ibb.co/L6M3SkQ/evaluate.png" alt="evaluate" width="80%" data-v-127ef020 data-v-127ef020> 
<p data-v-127ef020 data-v-127ef020><span style="font-size:12px" data-v-127ef020 data-v-127ef020>Fig. 3. Confusion matrix after the optimization phase.</span>
<br data-v-127ef020 data-v-127ef020></p>
</div>
<h3 id="improvements-for-real-use" data-v-127ef020 data-v-127ef020><a href="#improvements-for-real-use" aria-hidden="true" tabindex="-1" data-v-127ef020 data-v-127ef020><span class="icon icon-link" data-v-127ef020 data-v-127ef020></span></a>Improvements for real use</h3>
<p data-v-127ef020 data-v-127ef020>Given the poor performance of the model and considered the fact that the images acquired
by a webcam may be "different" from those present in the dataset, we decided to add some
"improvements" for real use.
We first introduced a <strong data-v-127ef020 data-v-127ef020>Confirmation Window</strong>, to stabilize the model predictions over
a higher frame number.
The confirmation window, implemented as a queue, collects the emotions of the last 20
frames and returns the value only if the dominant emotion is present in more than 60%
of the frames. If this condition is not satisfied, "Neutral" is returned, indicating
that the model is not fully convinced of the emotions collected in the last 20 frames.</p>
<p data-v-127ef020 data-v-127ef020>A confirmation window is associated for each recognized person, so as not to mix
predictions related to different faces.
<strong data-v-127ef020 data-v-127ef020>The benefit this implementation has brought is that the feeling that the model
is wrong has drastically reduced</strong>.</p>
<h2 id="building-freenect-and-the-python-wrapper" data-v-127ef020 data-v-127ef020><a href="#building-freenect-and-the-python-wrapper" aria-hidden="true" tabindex="-1" data-v-127ef020 data-v-127ef020><span class="icon icon-link" data-v-127ef020 data-v-127ef020></span></a>Building Freenect and the python wrapper</h2>
<p data-v-127ef020 data-v-127ef020>The code can run also on a generic camera, but we used the Kinect to take advantage of
the depth sensor to decrease false positives.
We built its drivers on Mac OS, based on the Homebrew method described at the following
link: <a href="https://openkinect.org/wiki/Getting_Started#OS_X" rel="nofollow noopener noreferrer" target="_blank" data-v-127ef020 data-v-127ef020>https://openkinect.org/wiki/Getting_Started#OS_X</a>.
With Homebrew you can easily install the Kinect v1 drivers.</p>
<p data-v-127ef020 data-v-127ef020>Kinect's depth camera helped us to segment and filter objects based on depth.
This allows us to reduce the number of false positives of face detection.
Since there is no rejection threshold for face recognition, limiting false positives
also allows the predictions contained in the confirmation window to be "not dirty",
thus resulting in a reliable prediction.</p>
<br data-v-127ef020 data-v-127ef020>
<h2 id="do-not-forgive-optimization" data-v-127ef020 data-v-127ef020><a href="#do-not-forgive-optimization" aria-hidden="true" tabindex="-1" data-v-127ef020 data-v-127ef020><span class="icon icon-link" data-v-127ef020 data-v-127ef020></span></a>Do not forgive Optimization</h2>
<p data-v-127ef020 data-v-127ef020>After deciding that the chosen model had performances in line with what was expected,
we moved on to the optimization phase, to obtain better hyperparameters and therefore a
higher accuracy.
We used optuna, an optimization framework specifically designed for this task.</p>
<p data-v-127ef020 data-v-127ef020>The hyperparameters we have optimized are:</p>
<div class="nuxt-content-highlight" data-v-127ef020 data-v-127ef020><pre class="line-numbers language-python" data-v-127ef020 data-v-127ef020><code data-v-127ef020 data-v-127ef020>   <span class="token string" data-v-127ef020 data-v-127ef020>'lr'</span><span class="token punctuation" data-v-127ef020 data-v-127ef020>:</span> learning rate<span class="token punctuation" data-v-127ef020 data-v-127ef020>,</span> uniform distribution <span class="token keyword" data-v-127ef020 data-v-127ef020>from</span> <span class="token number" data-v-127ef020 data-v-127ef020>1e-5</span> to <span class="token number" data-v-127ef020 data-v-127ef020>1e-1</span><span class="token punctuation" data-v-127ef020 data-v-127ef020>,</span>
   <span class="token string" data-v-127ef020 data-v-127ef020>'decay'</span><span class="token punctuation" data-v-127ef020 data-v-127ef020>:</span> lr decay<span class="token punctuation" data-v-127ef020 data-v-127ef020>,</span> uniform distribution <span class="token keyword" data-v-127ef020 data-v-127ef020>from</span> <span class="token number" data-v-127ef020 data-v-127ef020>1e-7</span> to <span class="token number" data-v-127ef020 data-v-127ef020>1e-4</span><span class="token punctuation" data-v-127ef020 data-v-127ef020>,</span>
   <span class="token string" data-v-127ef020 data-v-127ef020>'dropout'</span><span class="token punctuation" data-v-127ef020 data-v-127ef020>:</span> uniform distribution <span class="token keyword" data-v-127ef020 data-v-127ef020>from</span> <span class="token number" data-v-127ef020 data-v-127ef020>0.10</span> to <span class="token number" data-v-127ef020 data-v-127ef020>0.50</span><span class="token punctuation" data-v-127ef020 data-v-127ef020>,</span>
   <span class="token string" data-v-127ef020 data-v-127ef020>'l2'</span><span class="token punctuation" data-v-127ef020 data-v-127ef020>:</span> l2 regularization <span class="token keyword" data-v-127ef020 data-v-127ef020>in</span> Conv2D layers<span class="token punctuation" data-v-127ef020 data-v-127ef020>,</span> uniform distribution <span class="token keyword" data-v-127ef020 data-v-127ef020>from</span> <span class="token number" data-v-127ef020 data-v-127ef020>0.01</span> to <span class="token number" data-v-127ef020 data-v-127ef020>0.05</span><span class="token punctuation" data-v-127ef020 data-v-127ef020>,</span>
   <span class="token string" data-v-127ef020 data-v-127ef020>'kernel_size'</span><span class="token punctuation" data-v-127ef020 data-v-127ef020>:</span> <span class="token keyword" data-v-127ef020 data-v-127ef020>for</span> Conv2D layers <span class="token keyword" data-v-127ef020 data-v-127ef020>in</span> <span class="token builtin" data-v-127ef020 data-v-127ef020>range</span> <span class="token punctuation" data-v-127ef020 data-v-127ef020>[</span><span class="token number" data-v-127ef020 data-v-127ef020>3</span><span class="token punctuation" data-v-127ef020 data-v-127ef020>,</span> <span class="token number" data-v-127ef020 data-v-127ef020>5</span><span class="token punctuation" data-v-127ef020 data-v-127ef020>]</span><span class="token punctuation" data-v-127ef020 data-v-127ef020>,</span>
   <span class="token string" data-v-127ef020 data-v-127ef020>'batch_size'</span><span class="token punctuation" data-v-127ef020 data-v-127ef020>:</span> <span class="token keyword" data-v-127ef020 data-v-127ef020>in</span> <span class="token builtin" data-v-127ef020 data-v-127ef020>range</span> <span class="token punctuation" data-v-127ef020 data-v-127ef020>[</span><span class="token number" data-v-127ef020 data-v-127ef020>16</span><span class="token punctuation" data-v-127ef020 data-v-127ef020>,</span> <span class="token number" data-v-127ef020 data-v-127ef020>32</span><span class="token punctuation" data-v-127ef020 data-v-127ef020>,</span> <span class="token number" data-v-127ef020 data-v-127ef020>64</span><span class="token punctuation" data-v-127ef020 data-v-127ef020>,</span> <span class="token number" data-v-127ef020 data-v-127ef020>128</span><span class="token punctuation" data-v-127ef020 data-v-127ef020>]</span><span class="token punctuation" data-v-127ef020 data-v-127ef020>,</span>
</code></pre></div>
<p data-v-127ef020 data-v-127ef020>The best hyperparameters, found in 50 iterations, are:</p>
<div class="nuxt-content-highlight" data-v-127ef020 data-v-127ef020><pre class="line-numbers language-python" data-v-127ef020 data-v-127ef020><code data-v-127ef020 data-v-127ef020>   <span class="token string" data-v-127ef020 data-v-127ef020>'lr'</span><span class="token punctuation" data-v-127ef020 data-v-127ef020>:</span> <span class="token number" data-v-127ef020 data-v-127ef020>6.454516989719096e-05</span><span class="token punctuation" data-v-127ef020 data-v-127ef020>,</span>
   <span class="token string" data-v-127ef020 data-v-127ef020>'decay'</span><span class="token punctuation" data-v-127ef020 data-v-127ef020>:</span> <span class="token number" data-v-127ef020 data-v-127ef020>4.461966074951546e-05</span><span class="token punctuation" data-v-127ef020 data-v-127ef020>,</span>
   <span class="token string" data-v-127ef020 data-v-127ef020>'dropout'</span><span class="token punctuation" data-v-127ef020 data-v-127ef020>:</span> <span class="token number" data-v-127ef020 data-v-127ef020>0.3106791934814161</span><span class="token punctuation" data-v-127ef020 data-v-127ef020>,</span>
   <span class="token string" data-v-127ef020 data-v-127ef020>'l2'</span><span class="token punctuation" data-v-127ef020 data-v-127ef020>:</span> <span class="token number" data-v-127ef020 data-v-127ef020>0.04370766874155845</span><span class="token punctuation" data-v-127ef020 data-v-127ef020>,</span>
   <span class="token string" data-v-127ef020 data-v-127ef020>'kernel_size'</span><span class="token punctuation" data-v-127ef020 data-v-127ef020>:</span> <span class="token number" data-v-127ef020 data-v-127ef020>2</span><span class="token punctuation" data-v-127ef020 data-v-127ef020>,</span>
   <span class="token string" data-v-127ef020 data-v-127ef020>'batch_size'</span><span class="token punctuation" data-v-127ef020 data-v-127ef020>:</span> <span class="token number" data-v-127ef020 data-v-127ef020>32</span><span class="token punctuation" data-v-127ef020 data-v-127ef020>,</span>
</code></pre></div>
<p data-v-127ef020 data-v-127ef020>with a test loss of: <code data-v-127ef020 data-v-127ef020>1.0534</code>, and test accuracy of: <code data-v-127ef020 data-v-127ef020>66.035%</code>.
The optimization phase added a few percentage points to the average accuracy; however we
can affirm that the perceived performances are much higher. The advice we give is
therefore not to forget the optimization phase; 4-5 percentage points are not many and do
not upset the performance of a poor-performing model, but they can still make a difference.</p>
<br data-v-127ef020 data-v-127ef020>
<h2 id="prepare-for-production-with-onnx" data-v-127ef020 data-v-127ef020><a href="#prepare-for-production-with-onnx" aria-hidden="true" tabindex="-1" data-v-127ef020 data-v-127ef020><span class="icon icon-link" data-v-127ef020 data-v-127ef020></span></a>Prepare for production with ONNX</h2>
<p data-v-127ef020 data-v-127ef020>To speed up the inference phase, we setup up the ONNX conversion and runtime tools.
After choosing the best hyperparameters for the emotion model, we trained it and got
an optimized Keras model.
So we converted it to a ONNX model.
Generally speaking, the ONNX model version is much faster than the Keras one.
This leads a less power consumption and a higher FPS for our video application.
On our machines (CPU based, no NVIDIA), the ONNX model is around 25x faster than keras
version.</p>
<p data-v-127ef020 data-v-127ef020>These are the results:</p>
<div class="nuxt-content-highlight" data-v-127ef020 data-v-127ef020><pre class="line-numbers language-text" data-v-127ef020 data-v-127ef020><code data-v-127ef020 data-v-127ef020>Keras predictor 100 times  -  Elapsed: 3.177694320678711; mean: 0.03177694320678711
ONNX predictor  100 times  -  Elapsed: 0.119029283523559; mean: 0.00119029283523559
Factor: 26.696.
</code></pre></div>
<div class="nuxt-content-highlight" data-v-127ef020 data-v-127ef020><pre class="line-numbers language-text" data-v-127ef020 data-v-127ef020><code data-v-127ef020 data-v-127ef020>Keras predictor 10000 times  -  Elapsed: 317.5036771297455; mean: 0.03175036771297455
ONNX predictor  10000 times  -  Elapsed:  11.5271108150482; mean: 0.00115271108150482
Factor: 27.544.
</code></pre></div>
<br data-v-127ef020 data-v-127ef020>
<h2 id="conclusions" data-v-127ef020 data-v-127ef020><a href="#conclusions" aria-hidden="true" tabindex="-1" data-v-127ef020 data-v-127ef020><span class="icon icon-link" data-v-127ef020 data-v-127ef020></span></a>Conclusions</h2>
<p data-v-127ef020 data-v-127ef020>Although the recognition of faces and emotions is not a new topic, it was interesting
to approach a challenging dataset, applying all the best practices that are used to
bring a solution into production.
The task was difficult mainly due to the implications of using a very unbalanced,
very heterogeneous dataset with few samples. We did a statistical analysis, but
decided not to oversample and treat the dataset as it was.
In order not to make things easier for us, we have decided not to do transfer
learning from a pre-trained model.</p>
<p data-v-127ef020 data-v-127ef020>The optimization phase was fundamental to obtain
an accuracy of approximately 5% more. Although, accuracy is not perfectly indicative
of such an unbalanced dataset, the model's perceived performance after optimization
was much more satisfactory.
The use of <strong data-v-127ef020 data-v-127ef020>confirmation windows also made a big difference</strong>; they are not a new
technique, but they help tremendously in correcting false positives and increasing
perceived performance.
Finally, the use of <strong data-v-127ef020 data-v-127ef020>ONNX</strong> was important to achieve a performance boost on
the CPU and make the application usable in real time, reaching an average of 30 frames
processed per second on discrete computers.</p></div></article></div></div> <div class="client-only-placeholder" data-v-127ef020 data-v-127ef020>loading...</div></div></div></div></div></main> <footer id="footer" class="v-footer v-sheet theme--dark v-footer--padless toolbars" data-v-7404ace8 data-v-e6ffbd9e><svg viewBox="0 0 120 28" class="footer-svg" data-v-7404ace8><defs data-v-7404ace8><path id="wave" d="M 0,10 C 30,10 30,15 60,15 90,15 90,10 120,10 150,10 150,15 180,15 210,15 210,10 240,10 v 28 h -240 z" data-v-7404ace8></path></defs> <use id="wave3" xlink:href="#wave" x="0" y="-2" class="wave" data-v-7404ace8></use> <use id="wave2" xlink:href="#wave" x="0" y="0" class="wave" data-v-7404ace8></use> <use id="wave1" xlink:href="#wave" x="0" y="1" class="wave" data-v-7404ace8></use></svg> <div class="text-center footer-content v-card v-sheet theme--dark elevation-0 rounded-0" style="width:100%" data-v-7404ace8><div class="container pa-2" data-v-7404ace8><div class="row mx-2 align-center" data-v-7404ace8><div class="col" data-v-7404ace8><hr role="separator" aria-orientation="horizontal" class="v-divider theme--dark" data-v-7404ace8></div> <div class="col" data-v-7404ace8><span class="overline" style="font-size:16px!important" data-v-7404ace8>Stay in touch</span></div> <div class="col" data-v-7404ace8><hr role="separator" aria-orientation="horizontal" class="v-divider theme--dark" data-v-7404ace8></div></div></div> <div class="v-card__text py-2" data-v-7404ace8><div class="row align-center justify-center" data-v-7404ace8><div class="pa-2 col-md-6 col-12" data-v-7404ace8><div class="container pa-2" data-v-7404ace8><div class="row mt-4 align-center justify-center" data-v-7404ace8><h2 data-v-7404ace8>Social</h2></div> <div class="row my-2 py-2 align-center justify-center" data-v-7404ace8><a href="https://www.facebook.com/gioelecrispo" target="_blank" class="mx-2 v-btn v-btn--icon v-btn--round theme--dark v-size--default" data-v-7404ace8><span class="v-btn__content"><i aria-hidden="true" class="v-icon notranslate mdi mdi-facebook theme--dark" style="font-size:24px" data-v-7404ace8></i></span></a><a href="https://www.linkedin.com/in/gioele-crispo/" target="_blank" class="mx-2 v-btn v-btn--icon v-btn--round theme--dark v-size--default" data-v-7404ace8><span class="v-btn__content"><i aria-hidden="true" class="v-icon notranslate mdi mdi-linkedin theme--dark" style="font-size:24px" data-v-7404ace8></i></span></a><a href="https://www.instagram.com/gioelecrispo" target="_blank" class="mx-2 v-btn v-btn--icon v-btn--round theme--dark v-size--default" data-v-7404ace8><span class="v-btn__content"><i aria-hidden="true" class="v-icon notranslate mdi mdi-instagram theme--dark" style="font-size:24px" data-v-7404ace8></i></span></a><a href="https://www.youtube.com/channel/UCX38YLmygw3cfwljiNlBBQw" target="_blank" class="mx-2 v-btn v-btn--icon v-btn--round theme--dark v-size--default" data-v-7404ace8><span class="v-btn__content"><i aria-hidden="true" class="v-icon notranslate mdi mdi-youtube theme--dark" style="font-size:24px" data-v-7404ace8></i></span></a></div> <div class="row mt-4 pt-8 align-center justify-center" data-v-7404ace8><h2 data-v-7404ace8>Contacts</h2></div> <div class="row my-2 py-2 align-center justify-center" data-v-7404ace8><i aria-hidden="true" class="v-icon notranslate ml-3 mr-1 mdi mdi-at theme--dark" data-v-7404ace8></i> <span data-v-7404ace8>crispogioele@gmail.com</span> <i aria-hidden="true" class="v-icon notranslate ml-3 mr-1 mdi mdi-skype theme--dark" data-v-7404ace8></i> <span data-v-7404ace8>gioele.crispo</span></div></div></div> <div class="pa-2 col-md-5 col-11" data-v-7404ace8><div data-v-0e20c5a4 data-v-7404ace8><form novalidate class="v-form" data-v-0e20c5a4><div class="v-input v-input--dense theme--dark v-text-field v-text-field--filled v-text-field--enclosed v-text-field--outlined" data-v-0e20c5a4><div class="v-input__control"><div class="v-input__slot"><fieldset aria-hidden="true"><legend style="width:0"><span class="notranslate">​</span></legend></fieldset><div class="v-text-field__slot"><label for="input-1005" class="v-label theme--dark" style="left:0;right:auto;position:absolute">Name</label><input required id="input-1005"></div></div><div class="v-text-field__details"><div class="v-messages theme--dark"><div class="v-messages__wrapper"></div></div></div></div></div> <div class="v-input v-input--dense theme--dark v-text-field v-text-field--filled v-text-field--enclosed v-text-field--outlined" data-v-0e20c5a4><div class="v-input__control"><div class="v-input__slot"><fieldset aria-hidden="true"><legend style="width:0"><span class="notranslate">​</span></legend></fieldset><div class="v-text-field__slot"><label for="input-1008" class="v-label theme--dark" style="left:0;right:auto;position:absolute">Your E-mail</label><input required id="input-1008"></div></div><div class="v-text-field__details"><div class="v-messages theme--dark"><div class="v-messages__wrapper"></div></div></div></div></div> <div class="v-input v-textarea v-input--dense theme--dark v-text-field v-text-field--filled v-text-field--enclosed v-text-field--outlined" data-v-0e20c5a4><div class="v-input__control"><div class="v-input__slot"><fieldset aria-hidden="true"><legend style="width:0"><span class="notranslate">​</span></legend></fieldset><div class="v-text-field__slot"><label for="input-1011" class="v-label theme--dark" style="left:0;right:auto;position:absolute">Your message for me</label><textarea required id="input-1011" rows="5"></textarea></div></div><div class="v-text-field__details"><div class="v-messages theme--dark"><div class="v-messages__wrapper"></div></div></div></div></div> <button type="button" disabled class="mr-4 v-btn v-btn--disabled v-btn--has-bg v-btn--rounded theme--dark v-size--default" data-v-0e20c5a4><span class="v-btn__content">
            Send Message
        </span></button></form> <div class="v-dialog__container" data-v-0e20c5a4><!----></div></div></div></div></div> <div class="v-card__text pt-6 pb-4" data-v-7404ace8><blockquote class="subheader pa-0" data-v-7404ace8>
                You can not discover new oceans if you do not have the courage to
                lose sight of the shore.
            </blockquote></div> <hr role="separator" aria-orientation="horizontal" class="v-divider theme--dark" data-v-7404ace8> <div class="v-card__text py-4" data-v-7404ace8><div class="row" data-v-7404ace8><div class="py-1 col-sm-6 col-12" data-v-7404ace8>2022 — <span class="subtitle-1" data-v-7404ace8>Gioele Crispo</span></div> <div class="py-1 col-sm-6 col-12" data-v-7404ace8><span data-v-52319016 data-v-7404ace8><a class="mx-2 mb-1 terms" data-v-52319016><span data-v-52319016>Terms and policy</span> <i aria-hidden="true" class="v-icon notranslate ml-3 mdi mdi-information-outline theme--dark" style="font-size:20px" data-v-52319016></i></a> <div class="v-dialog__container" data-v-52319016><!----></div></span></div></div></div></div></footer></div></div></div></div><script defer src="/_nuxt/static/1648122739/blog/a-complete-ml-pipeline-study-case-face-and-emotion-recognition/state.js"></script><script src="/_nuxt/64d805e.js" defer></script><script src="/_nuxt/bbb0136.js" defer></script><script src="/_nuxt/96c6ddd.js" defer></script><script src="/_nuxt/19e3453.js" defer></script><script src="/_nuxt/1e35afa.js" defer></script>
  </body>
</html>
